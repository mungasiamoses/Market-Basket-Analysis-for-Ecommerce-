{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('Ecommerce Dataset.csv')\n",
    "df_new=pd.read_csv('TBC_Ecommerce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df =df.rename(columns={'Order number': 'Order_number'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SKU'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =df.groupby(['Order_number','SKU'])[['SKU']].count().T\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =df.groupby(['Order_number','SKU']).count()[['Date placed']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df.groupby(['Order_number','SKU']).count()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "keys =[SKU for SKU, df in df.groupby(['SKU'])]\n",
    "plt.bar(keys,df.groupby(['SKU']).count()['Order number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "keys =[SKU for SKU, df in df.groupby(['SKU'])]\n",
    "pd.DataFrame(keys,df.groupby(['SKU']).count()['Order_number']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKU_group.count()['Order_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load apriori and association package from mlxtend. \n",
    "Used different dataset because mlxtend need data in below format. \n",
    "\n",
    "             itemname  apple banana grapes\n",
    "transaction  1            0    1     1\n",
    "             2            1    0     1  \n",
    "             3            1    0     0\n",
    "             4            0    1     0\n",
    "             \n",
    " we could have used above data as well but need to perform operation to bring in this format instead of that used seperate data only.            \n",
    "'''\n",
    "\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "df1 = pd.read_csv('TBC_Ecommerce.csv', encoding=\"ISO-8859-1\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data has many country choose any one for check..\n",
    "df1.SKU.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data in format which it require converting using pivot table and Quantity sum as values. fill 0 if any nan values\n",
    "\n",
    "basket = pd.pivot_table(data=df1,index='Order number',columns='Product',values='Quantity', \\\n",
    "                        aggfunc='sum',fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this to check correctness after binning it to 1 at below code..\n",
    "basket['What the Dog Saw (Penguin)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dont need quantity sum we need either has taken or not so if user has taken that item mark as 1 else he has not taken 0.\n",
    "\n",
    "def convert_into_binary(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_sets = basket.applymap(convert_into_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above steps we can same item has quantity now converted to 1 or 0.\n",
    "basket_sets['The Wolf of Wall Street'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call apriori function and pass minimum support here we are passing 7%. means 7 times in total number of transaction that item was present.\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.002, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it will generate frequent itemsets using two step approch\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have association rules which need to put on frequent itemset. here we are setting based on lift and has minimum lift as 1\n",
    "rules_mlxtend = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules_mlxtend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules_mlxtend.rename(columns={'antecedents':'lhs','consequents':'rhs'})\n",
    "\n",
    "# as based business use case we can sort based on confidance and lift.\n",
    "rules_mlxtend[ (rules_mlxtend['lift'] >= 4) & (rules_mlxtend['confidence'] >= 0.8) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directed graph below is built for this rule and shown below. it will have always incoming and outcoming edges. Incoming edge(s) will represent antecedants and the stub (arrow) will be next to node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting output in a graph plot.\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "def draw_graph(rules, rules_to_show):\n",
    "    G1 = nx.DiGraph()\n",
    "    color_map=[]\n",
    "    N = 50\n",
    "    colors = np.random.rand(N)    \n",
    "    strs=['R0', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11']\n",
    "\n",
    "    for i in range(rules_to_show):\n",
    "        G1.add_nodes_from([\"R\"+str(i)])\n",
    "        for a in rules.iloc[i]['antecedents']:\n",
    "            G1.add_nodes_from([a])\n",
    "            G1.add_edge(a, \"R\"+str(i), color=colors[i] , weight = 2)\n",
    "        for c in rules.iloc[i]['consequents']:\n",
    "            G1.add_nodes_from([c])\n",
    "            G1.add_edge(\"R\"+str(i), c, color=colors[i],  weight=2)\n",
    "\n",
    "    for node in G1:\n",
    "        found_a_string = False\n",
    "        for item in strs: \n",
    "            if node==item:\n",
    "                found_a_string = True\n",
    "        if found_a_string:\n",
    "            color_map.append('yellow')\n",
    "        else:\n",
    "            color_map.append('green')       \n",
    "\n",
    "    edges = G1.edges()\n",
    "    colors = [G1[u][v]['color'] for u,v in edges]\n",
    "    weights = [G1[u][v]['weight'] for u,v in edges]\n",
    "\n",
    "    pos = nx.spring_layout(G1, k=16, scale=1)\n",
    "    nx.draw(G1, pos, edges=edges, node_color = color_map, edge_color=colors, width=weights, font_size=16, \n",
    "            with_labels=False)            \n",
    "\n",
    "    for p in pos:  # raise text positions\n",
    "        pos[p][1] += 0.07\n",
    "        nx.draw_networkx_labels(G1, pos)\n",
    "        plt.show()\n",
    "\n",
    "draw_graph (rules_mlxtend, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
